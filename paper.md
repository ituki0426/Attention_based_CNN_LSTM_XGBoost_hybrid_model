# Abstract

株式市場は経済発展において重要な役割を果たしている。

株式市場の複雑な変動性により、株価の変動に関する研究と予測は、投資家のリスク回避に役立つ可能性がある。

従来の時系列モデルであるARIMAは非線形性をうまく表現できず、株価予測において満足のいく結果を得ることができない。

ニューラルネットワークは強力な非線形一般化能力を有しているため、本論文では、注意機構（Attention）を用いたCNN-LSTMとXGBoostのハイブリッドモデルを提案し、株価を予測する。

この論文で構築されたモデルは、時系列モデル、注意機構を備えた畳み込みニューラルネットワーク（CNN）、長短期記憶ネットワーク（LSTM）、およびXGBoost回帰器を統合し、非線形関係を効果的に捉え、予測精度を向上させる。

本モデルは、複数の期間にわたる株式市場の履歴情報を完全に抽出することができる。

株式データはまずARIMAを用いて前処理される。

その後、事前学習・ファインチューニングのフレームワークに基づいて構築された深層学習アーキテクチャが採用される。

事前学習モデルには、シーケンス間フレームワークに基づく注意機構付きCNN-LSTMモデルが用いられる。

モデルはまず畳み込みにより元のデータから深層特徴量を抽出し、その後、長期依存性のある時系列特徴を抽出するためにLSTMネットワークを用いる。

最終的に、XGBoostモデルを用いてファインチューニングが行われる。
実験結果は、このハイブリッドモデルがより効果的であり、予測精度も比較的高いことを示している。

これは、投資家や機関が意思決定を行い、収益拡大およびリスク回避という目的を達成するのに役立つ可能性がある。

# 1.Introduction

株式市場は経済発展において重要な役割を果たしています。

株式は高い収益特性を持つため、株式市場は機関投資家や個人投資家からますます注目を集めています。

しかし、株式市場は変動が複雑であるため、時には機関や投資家に多大な損失をもたらすこともあります。

株式市場のリスクを考慮すると、株価の変動に関する研究や予測は、投資家がリスクを回避する上で有効です。

従来の時系列モデルであるARIMAは、非線形な時系列を記述することができず、モデリングの前に多くの前提条件を満たす必要があり、株価予測において顕著な成果を上げることができませんでした。

近年では、人工知能の理論および技術の急速な発展に伴い、より多くの研究者が金融市場に人工知能手法を応用するようになっています。

一方で、自然言語の系列、タンパク質配列、株価の系列など、系列モデリングの課題は人工知能研究の分野において重要な位置を占めています [8], [12]。

中でも最も代表的な人工知能手法はニューラルネットワークであり、これは強力な非線形の一般化能力を有しています。

リカレントニューラルネットワーク（RNN）は、ニューラルネットワークアーキテクチャを用いて時系列データを解析するために採用されており、その中でも長短期記憶（LSTM）モデルが最も一般的に使用されるRNNです。LSTMはRNNにゲート機構を導入しており、これは人間の記憶を模倣するものとみなすことができます。つまり、人間が有用な情報を記憶し、不要な情報を忘れるように、LSTMも同様の処理を行うことができます [6]。

注意機構（Attention Mechanism） [7], [15] もまた、人間の注意力を模倣したものとみなすことができ、人間が有用な情報に注意を向け、無用な情報を無視するような機構です。

注意機構を組み込んだ畳み込みニューラルネットワーク（ACNN） は、時系列モデリングにおいて広く使用されています [4], [10]。

注意ベースの畳み込みニューラルネットワークとLSTMを組み合わせたものとして、自己注意（self-attention）に基づく系列変換モデル（seq2seq） [14] があり、時系列データのエンコードおよびデコードに用いられます。

このモデルはLSTMの持つ長期依存関係の問題を解決できるため、長い系列のモデリングに優れています。LSTMはLSTM構造に適合する特定の長距離依存関係を捉えることができ、一方でACNNは局所的かつグローバルな対応関係の両方を捉えることができます。

したがって、このアーキテクチャはより柔軟で堅牢です。

Transformer [15] は、自己注意機構に基づく時系列学習モデルの中で最も成功したモデルです。

自然言語処理における実験により、Transformer は長い系列をより良くモデル化できることが示されています。

事前学習を施した双方向エンコーダ表現型 Transformer（BERT）[2] は、基本的な Transformer よりも高い性能を発揮することができます。

事前学習（pretraining） は、Transformer（BERT）の性能を大幅に向上させる手法の一つです。

本論文では、株価を予測するためのハイブリッド深層学習モデルを提案します。従来のハイブリッド予測モデルとは異なり、本提案モデルは時系列モデルARIMAとニューラルネットワークを非線形的に統合しており、両者の基本モデルの利点を組み合わせることで、予測精度の向上を実現しています。

まず、株価データはARIMAモデルによって前処理されます（ARIMA(p=2, q=0, d=1) を使用）。前処理後の株価系列は、ニューラルネットワーク（NN）またはXGBoostに入力されます。

その後、事前学習—ファインチューニング（pretraining-finetuning）フレームワーク[2], [5]に基づく深層学習アーキテクチャが採用されます。事前学習モデルとしては、AttentionベースのCNN-LSTMモデル（sequence-to-sequenceフレームワークに基づく）が使用されます。このモデルでは、AttentionベースのCNNがエンコーダ、Bidirectional LSTMがデコーダの役割を果たします。

モデルはまず、畳み込み処理（convolution）によって元の株価データの深層特徴を抽出し、次にLSTMネットワークを用いて長期的な時系列特徴を掘り起こします。最後に、XGBoostモデルをファインチューニングに用いることで、株式市場における複数期間の情報を十分に活用することができます。

本提案のAttentionベースCNN-LSTMとXGBoostのハイブリッドモデルは、AttCLXと呼ばれます。

実験結果は、本モデルがより効果的であり、予測精度が比較的高いことを示しています。これにより、投資家や機関は意思決定を行いやすくなり、収益の拡大やリスク回避といった目的を達成する手助けとなります。

# 2.Materials and Methods

## A.ARIMA

古典的な株価予測手法は、ARMA（自己回帰移動平均：Auto Regressive Moving Average）モデルおよびARIMA（自己回帰和分移動平均：Auto Regressive Integrated Moving Average）モデルに基づいています。

ARMA(p, q)モデルは以下のように表されます：

$$
s_t = a_0 + \sum_{i=1}^{p} a_i s_{t-i} + w_t + \sum_{i=1}^{q} b_i w_{t-i}, \tag{1}
$$

ここで $a, b$ はパラメータ、$w$ はノイズです。

ARMAモデルは、時系列 $s_{1:N}$ が**定常性（stationary）**を満たすときに使用される。

定常性とは時間経過にかかわらず平均、分散、自己相関が変化しない時系列データのことです。

つまり、次の条件を満たす場合です：

$$
\mathbb{E}[s_t] = \text{一定} \tag{2}
$$

$$
\mathrm{Cov}(s_t, s_{t-k}) = \text{一定} \tag{3}
$$

ここで $t = 1, 2, \ldots, N$、$k = 1, 2, \ldots, t$ とします。


一方、系列が**非定常性（non-stationary）**である場合、ARIMA(p, q, d)モデルでは、d階差分を適用して定常系列へと変換します。

株価予測においては、一次差分 $x_{1:N} = \dot{s}_{1:N}$（すなわち、$x_k = s_k - s_{k-1}$）が定常系列として扱われることが一般的です。

系列が非定常である場合、ARIMA(p, q, d) モデルでは、**d階差分（difference）**をとることで定常系列に変換します。

株価予測では、一次差分 $x_{1:N} = \dot{s}_{1:N}$（すなわち $x_k = s_k - s_{k-1}$）が通常、定常系列とみなされます。

---

時系列の**定常性を検定するためにADF（Augmented Dickey-Fuller）検定**を用いました。

元の時系列データと一次差分系列の両方にADF検定を適用しています。

結果は Table I および Table II に示されています。

- **p値（p-value）が0.562より大きい**場合、
- または **1%の有意水準における臨界値（Critical Value）が-3.44より大きい**場合、

その系列は**非定常である**と判断されます。

ADF検定の結果、**元の系列は非定常であり、一次差分系列は定常である**ことが示されました。

一次差分系列および二次差分系列のグラフは、それぞれ**Fig.1 および Fig.2**に示されています。

## B.Deep Learnign on Sequential data

## C.Attention mechanism

## D.Method

# 3.Experiments

## A.Modification of model

## B.Prediction performance